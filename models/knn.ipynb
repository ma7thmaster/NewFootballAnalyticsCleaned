{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data from data extraction\n",
    "#### First import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lq/43nmsszn7jj8zr58hhw9fzkm0000gn/T/ipykernel_37327/1845606109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Accuracy: %.2f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Params: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "laligadf = pd.read_pickle('laligadfmod')\n",
    "y=laligadf['outcome']\n",
    "X=laligadf.loc[:, laligadf.columns!='outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.5, \n",
    "                                                    shuffle=True, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='ball_tree')\n",
    "param_grid = [{'n_neighbors': [3,5,27,15,20]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=knn,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=10,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "print(gs.cv_results_)\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "print('Test Accuracy: %.2f%%' % (gs.best_estimator_.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we noticed that the maximum neighbors had the highest accuracy so we thought testing around 20 next would be best in finding the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewvoss/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewvoss/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/matthewvoss/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/matthewvoss/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 566, in _fit\n",
      "    raise ValueError(\"Expected n_neighbors > 0. Got %d\" % self.n_neighbors)\n",
      "ValueError: Expected n_neighbors > 0. Got 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/matthewvoss/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.7803373  0.84881746 0.82169643 0.85060119 0.83859722\n",
      " 0.8594881  0.85371032 0.86349405 0.86037897 0.8630496  0.85815675\n",
      " 0.86393849 0.86393849 0.86660714 0.8661627  0.8683869  0.86705159\n",
      " 0.86660913 0.86660913 0.86660913 0.86660913 0.86705357 0.86660913\n",
      " 0.8661627  0.86660913 0.86571825 0.86616468 0.86616468 0.86616468]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 86.84%\n",
      "Best Params: {'n_neighbors': 16}\n",
      "Test Accuracy: 86.36%\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "laligadf = pd.read_pickle('laligadfmod')\n",
    "y=laligadf['outcome']\n",
    "X=laligadf.loc[:, laligadf.columns!='outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.5, \n",
    "                                                    shuffle=True, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm='ball_tree')\n",
    "param_grid = [{'n_neighbors': range(0,30)}]\n",
    "\n",
    "gs = GridSearchCV(estimator=knn,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=10,\n",
    "                    scoring='accuracy') \n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "print('Test Accuracy: %.2f%%' % (gs.best_estimator_.score(X_test,y_test)*100))\n",
    "ratio = 1-0.13358524116470327\n",
    "print(gs.best_estimator_.score(X_test,y_test)>ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN has a test accuracy little less than guessing every shot will be a miss. So, this classifier probably won't be very accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_train_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lq/43nmsszn7jj8zr58hhw9fzkm0000gn/T/ipykernel_37327/2460966307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# of neighbors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'"
     ]
    }
   ],
   "source": [
    "test_curve = gs.cv_results_['mean_test_score']\n",
    "train_curve = gs.cv_results_['mean_train_score']\n",
    "plt.plot(test_curve, label = 'train')\n",
    "plt.xlabel('# of neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Shawshank, could you please look into grid seach for this problem. I don't know to check both n_components and n_neighbors below\n",
    "n_neighbors = 16\n",
    "random_state = 0\n",
    "\n",
    "# Load Digits dataset\n",
    "laligadf = pd.read_pickle('laligadfmod')\n",
    "y=laligadf['outcome']\n",
    "X=laligadf.loc[:, laligadf.columns!='outcome']\n",
    "y=y.to_numpy()\n",
    "X=X.to_numpy()\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, stratify=y, random_state=random_state\n",
    ")\n",
    "nca = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    NeighborhoodComponentsAnalysis(n_components=6, random_state=random_state),\n",
    ")\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "nca.fit(X_train, y_train)\n",
    "\n",
    "knn.fit(nca.transform(X_train),y_train)\n",
    "\n",
    "acc_knn = knn.score(nca.transform(X_test), y_test)\n",
    "\n",
    "print(acc_knn)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e98ce8c2ba6bd25230aef0f4a7feaee408d998691e1b6fbf4fe750f0058d19"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
